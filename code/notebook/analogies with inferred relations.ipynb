{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up libraries and plotting UI\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set(rc={\"figure.figsize\": (10, 8), \"font.size\": 12})\n",
    "\n",
    "def matshow(mat, **kwargs):\n",
    "    seaborn.heatmap(mat, square=True, xticklabels=50, yticklabels=50, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from conceptnet_retrofitting.loaders import *\n",
    "from conceptnet_retrofitting.word_vectors import WordVectors\n",
    "from conceptnet_retrofitting.builders.build_assoc import build_relations_from_conceptnet\n",
    "from ordered_set import OrderedSet\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = '../build-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/rspeer/wobbly_data/code/conceptnet-retrofitting-paper/code/notebook'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = OrderedSet(load_labels(PATH + 'glove.840B.300d.filtered.conceptnet5.labels'))\n",
    "sparse_rels = build_relations_from_conceptnet(labels, '/wobbly/data/conceptnet5/assoc/reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b5052ffbbb6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mPATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'glove.840B.300d.filtered.conceptnet5.replacements.msgpack'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mglove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_word_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'glove.840B.300d.standardized.labels'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'glove.840B.300d.l1.standardized.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/media/rspeer/wobbly_data/code/conceptnet-retrofitting-paper/code/conceptnet_retrofitting/loaders.py\u001b[0m in \u001b[0;36mload_word_vectors\u001b[1;34m(labels_in, vecs_in, replacements_in, memmap)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mwv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordVectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mwv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordVectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstandardizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreplacements_in\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/media/rspeer/wobbly_data/code/conceptnet-retrofitting-paper/code/conceptnet_retrofitting/word_vectors.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, labels, vectors, replacements, standardizer)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mWordVectors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplacements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstandardizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnglove = load_word_vectors(\n",
    "    PATH + 'glove.840B.300d.filtered.conceptnet5.labels',\n",
    "    PATH + 'glove.840B.300d.l1.filtered.conceptnet5.npy',\n",
    "    PATH + 'glove.840B.300d.filtered.conceptnet5.replacements.msgpack'\n",
    ")\n",
    "glove = load_word_vectors(PATH + 'glove.840B.300d.standardized.labels', PATH + 'glove.840B.300d.l1.standardized.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from conceptnet_retrofitting.builders.retrofit import dense_relation_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_array = dense_relation_array(\n",
    "    cnglove.vectors[:100000],\n",
    "    {rel: sp[:100000, :100000] for (rel, sp) in sparse_rels.items()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def en_filter(term):\n",
    "    return term.startswith('/c/en/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_labels = sorted(sparse_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_analogies(filename):\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        line = line.rstrip()\n",
    "        if not line or line.startswith('#'):\n",
    "            continue\n",
    "        parts = line.split('\\t')\n",
    "        inputs = parts[1:4]\n",
    "        answers = parts[4:]\n",
    "        yield inputs, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sym_rel_array = np.concatenate([rel_array, rel_array.swapaxes(1, 2)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "any_rel = np.mean(cnglove.vectors, 0) @ rel_array @ np.mean(cnglove.vectors, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def which_relation(wv, rar, c1, c2):\n",
    "    rels = wv.to_vector(c2) @ rar @ wv.to_vector(c1)\n",
    "    diff = np.maximum(0, rels - any_rel) ** 2\n",
    "    diffsum = np.sum(diff)\n",
    "    if diffsum > 0:\n",
    "        diff /= diffsum\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank3_inner_product(vec, array3):\n",
    "    return (array3 * vec[:, np.newaxis, np.newaxis]).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_analogy(wv, rar, c1, c2, c3, c4):\n",
    "    if c4 in (c1, c2, c3):\n",
    "        return 0.\n",
    "    try:\n",
    "        relA = which_relation(wv, rar, c1, c2)\n",
    "        relB = which_relation(wv, rar, c1, c3)\n",
    "        relAr = rank3_inner_product(relA, rar)\n",
    "        relBr = rank3_inner_product(relB, rar)\n",
    "        v1, v2, v3, v4 = [wv.to_vector(c) for c in (c1, c2, c3, c4)]\n",
    "        numer1 = v4 @ relAr @ v3 + 1\n",
    "        numer2 = v4 @ relBr @ v2 + 1\n",
    "        denom1 = v4 @ relAr @ v1 + 1\n",
    "        denom2 = v4 @ relBr @ v1 + 1\n",
    "    except KeyError:\n",
    "        return 0.\n",
    "    return (numer1 ** 3 * numer2) / (denom1 + denom2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analogy(wv, rar, c1, c2, c3, num=20):\n",
    "    relA = which_relation(wv, rar, c1, c2)\n",
    "    relB = which_relation(wv, rar, c1, c3)\n",
    "    print(\"RelA\")\n",
    "    for label, strength in zip(rel_labels + rel_labels, relA):\n",
    "        print('\\t%-20s\\t% 7.1f' % (label, strength * 1000))\n",
    "    print(\"RelB\")\n",
    "    for label, strength in zip(rel_labels + rel_labels, relB):\n",
    "        print('\\t%-20s\\t% 7.1f' % (label, strength * 1000))\n",
    "    relAr = rank3_inner_product(relA, rar)\n",
    "    relBr = rank3_inner_product(relB, rar)\n",
    "    v1, v2, v3 = [wv.to_vector(c) for c in (c1, c2, c3)]\n",
    "    numer1 = wv.vectors @ (relAr @ v3) + 1\n",
    "    numer2 = wv.vectors @ (relBr @ v2) + 1\n",
    "    denom1 = wv.vectors @ (relAr @ v1) + 1\n",
    "    denom2 = wv.vectors @ (relBr @ v1) + 1\n",
    "    ratings = (numer1 ** 2 * numer2) / (denom1 + denom2)\n",
    "    sortorder = np.argsort(-ratings)\n",
    "    found = []\n",
    "    for idx in sortorder:\n",
    "        label = wv.labels[idx]\n",
    "        if en_filter(label):\n",
    "            found.append((label, ratings[idx]))\n",
    "        if len(found) >= num:\n",
    "            break\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.seterr(all='raise')\n",
    "analogy(cnglove, rel_array, 'fire', 'hot', 'snow', num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analogy_3cosmul(wv, c1, c2, c3, num=20):\n",
    "    sims1 = (wv.vectors @ wv.to_vector(c1)) + 1.000001\n",
    "    sims2 = (wv.vectors @ wv.to_vector(c2)) + 1\n",
    "    sims3 = (wv.vectors @ wv.to_vector(c3)) + 1\n",
    "    ratings = sims2 * sims3 / (sims1)\n",
    "    sortorder = np.argsort(-ratings)\n",
    "    found = []\n",
    "    for idx in sortorder:\n",
    "        label = wv.labels[idx]\n",
    "        if en_filter(label):\n",
    "            found.append((label, ratings[idx]))\n",
    "        if len(found) >= num:\n",
    "            break\n",
    "    return found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_analogy_3cosmul(wv, c1, c2, c3, c4):\n",
    "    try:\n",
    "        v4 = wv.to_vector(c4)\n",
    "        sim1 = v4 @ wv.to_vector(c1) + 1.000001\n",
    "        sim2 = v4 @ wv.to_vector(c2) + 1\n",
    "        sim3 = v4 @ wv.to_vector(c3) + 1\n",
    "    except KeyError:\n",
    "        return 0.\n",
    "    return sim2 * (sim3 ** 2) / sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_analogies(analogy_func, filename='/nfs/broadway/data/corpora/readtheory-analogies.txt'):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for inputs, answers in read_analogies(filename):\n",
    "        # The 'inputs' are the three given components of the analogy.\n",
    "        # 'answers' are the multiple-choice answers, where the correct answer is first in the list.\n",
    "        best_score = 0.\n",
    "        best_answer = ''\n",
    "        for answer in answers:\n",
    "            quad = inputs + [answer]\n",
    "            score = analogy_func(*quad)\n",
    "            if score >= best_score:\n",
    "                best_score = score\n",
    "                best_answer = answer\n",
    "        total += 1\n",
    "        if best_answer == answers[0]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            items = tuple(inputs + [best_answer.upper()] + [answers[0].upper()])\n",
    "            print(\"%s : %s :: %s : %s (should be %s)\" % items)\n",
    "    print(\"Score: %2.2f%% (%d/%d)\" % (correct / total * 100, correct, total))\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def curry_3cosmul(c1, c2, c3, c4):\n",
    "    return eval_analogy_3cosmul(cnglove, c1, c2, c3, c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def curry_inferred(c1, c2, c3, c4):\n",
    "    return eval_analogy(cnglove, rel_array, c1, c2, c3, c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('\\n3cosmul:')\n",
    "eval_analogies(curry_3cosmul)\n",
    "print('\\ninferred relations:')\n",
    "eval_analogies(curry_inferred)\n",
    "\n",
    "print('\\n3cosmul:')\n",
    "eval_analogies(curry_3cosmul, filename='/nfs/broadway/data/corpora/learningexpress-analogies.txt')\n",
    "print('\\ninferred relations:')\n",
    "eval_analogies(curry_inferred, filename='/nfs/broadway/data/corpora/learningexpress-analogies.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_words = ['metro', 'railway', 'subway', 'transit', 'public transit', 'public transportation', 'busway', 'light rail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatter_words(wv1, wv2, words):\n",
    "    N = len(words)\n",
    "    vectors1 = np.vstack([wv1.to_vector(word) for word in words])\n",
    "    vectors2 = np.vstack([wv2.to_vector(word) for word in words])\n",
    "    U, S, Vt = np.linalg.svd(np.concatenate([vectors1, vectors2], axis=0), full_matrices=False)\n",
    "    axis_ranks = np.argsort(Vt[0])\n",
    "    ax1, ax2 = axis_ranks[-1], axis_ranks[-2]\n",
    "    print(ax1, ax2)\n",
    "    xs1 = vectors1[:, ax1]\n",
    "    ys1 = vectors1[:, ax2]\n",
    "    xs2 = vectors2[:, ax1]\n",
    "    ys2 = vectors2[:, ax2]\n",
    "    plot1 = plt.scatter(xs1, ys1, marker='o', color='#8899ff', s=30, label='before retrofitting')\n",
    "    plot2 = plt.scatter(xs2, ys2, marker='s', color='#338833', s=30, label='after retrofitting')\n",
    "    plt.legend(handles=[plot1, plot2])\n",
    "    for i, word in enumerate(words):\n",
    "        #plt.annotate(\n",
    "        #    word, xy=(xs1[i], ys1[i]), xytext=(-2, 2),\n",
    "        #    textcoords='offset points', ha='right', va='bottom',\n",
    "        #    color='#6677dd'\n",
    "        #)\n",
    "        plt.annotate(\n",
    "            word, xy=(xs2[i], ys2[i]), xytext=(-3, 2),\n",
    "            textcoords='offset points', ha='right', va='bottom',\n",
    "            color='#333333'\n",
    "        )\n",
    "        plt.quiver(\n",
    "            xs1 * .95 + xs2 * .05, ys1 * .95 + ys2 * .05, (xs2 - xs1) * .9, (ys2 - ys1) * .9, scale_units='xy', angles='xy', scale=1,\n",
    "            width=.0005, headwidth=20, headlength=20, color='#777777'\n",
    "        )\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt = scatter_words(glove, cnglove, example_words)\n",
    "plt.xlim(-0.20, 0.05)\n",
    "plt.ylim(-0.20, 0.05)\n",
    "plt.xlabel(\"Feature with most variance\")\n",
    "plt.ylabel(\"Feature with second-most variance\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
